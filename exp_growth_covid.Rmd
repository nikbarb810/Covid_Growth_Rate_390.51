---
title: "Estimating rate of growth of SARS-CoV-2 in the European population"
output: html_document
date: "`r Sys.Date()`"
---

```{r}


#read observations
observed_file_path = "ms_obs_final.out"
obs_data = readLines(observed_file_path)




#read simulations
sim_file_path = "ms_sim_final.out"

# Read the file using readLines()
lines = readLines(sim_file_path)


# Specify the number of simulations
total_simulations = 10000

# Specify the number of rows per simulation
rows_per_simulation = 50

#final list containing all simulations
simulations = vector("list", total_simulations)

#formatting lines vector into simulations
for(curr_sim in 1:total_simulations) {
  start = curr_sim + (curr_sim - 1) * rows_per_simulation
  end = (curr_sim - 1) + curr_sim * rows_per_simulation
  
  simulations[[curr_sim]] = lines[start:end]
}

simulations

```



Our first parameter that we will calculate, will be the average number of pairwise differences between  all pairs of sequences. Below we have the implementation in R, but calling this function for all our simulations, severely slows the program down. 

The snippet after this one, shows a nice way to optimize the dreadfully slow for-loops that R uses, by "translating" the function, with the help of Rcpp, into cpp code that can be compiled and run significantly faster.

```{r}
library(stringdist)
library(Rcpp)



# calculates the pairwise difference between a pair of sequences.
pairwisediff <- function(arr1, arr2) {
  return (stringdist::stringdist(arr1, arr2, method = "hamming"))
}


# calculates the average number of pairwise difference between ALL pairs of sequences.
k_estimate <- function(simulation) {
  
  num_arrays = length(simulation)
  sum_diff = 0
  
  #sum all pairwise differences
  for(i in 1:(num_arrays - 1)) {
    for(j in (i + 1):num_arrays) {
      sum_diff = sum_diff + pairwisediff(simulation[[i]],simulation[[j]])
    }
  }
  
  
  #calculate average
  k_val = sum_diff / choose(num_arrays,2)
  
  return (k_val)
}
```


NOTE: Some packages might need to be installed in order to run Rcpp!

We can obtain the same functionality by the following cpp code, using Rcpp.

```{Rcpp}
#include <Rcpp.h>
using namespace Rcpp;

// Function to calculate pairwise differences
int pairwisediff_cpp(const std::string& str1, const std::string& str2) {
  int n = str1.size();
  int diff = 0;
  
  for (int i = 0; i < n; ++i) {
    if (str1[i] != str2[i]) {
      diff++;
    }
  }
  
  return diff;
}

// Function to calculate k estimate
// [[Rcpp::export]]
double k_estimate_cpp(const List& simulation) {
  int num_arrays = simulation.size();
  int sum_diff = 0;
  
  // Convert simulation indexes to C++ strings
  std::vector<std::string> strings(num_arrays);
  for (int i = 0; i < num_arrays; ++i) {
    strings[i] = Rcpp::as<std::string>(simulation[i]);
  }
  
  // Sum all pairwise differences
  for (int i = 0; i < (num_arrays - 1); ++i) {
    for (int j = (i + 1); j < num_arrays; ++j) {
      sum_diff += pairwisediff_cpp(strings[i], strings[j]);
    }
  }
  
  // Calculate average
  double k_val = static_cast<double>(sum_diff) / Rf_choose(num_arrays, 2);
  
  return k_val;
}

```



Below we can see a speed comparison between the 2 options, on a single random simulation that contains 2000 strings.
```{r}



# Set the length of the random vector
length <- 10

# Number of instances in the list
num_strings <- 2000


random_list <- replicate(num_strings, paste(sample(c("0", "1"), length, replace = TRUE), collapse = ""), simplify = FALSE)


# 96.38 seconds
exec_time <- system.time(k_estimate(random_list))
print(exec_time)

# 0.02 seconds
exec_time_cpp <- system.time(k_estimate_cpp(random_list))
print(exec_time_cpp)


```

We can definitely see that, implementing Rcpp code snippets, even in this small example has the potential to dramatically increase our performance.

But what's the difference in our actual database, which contains 10000 simulations of 50 strings each? 
```{r}

#calc time in r 
r_sims_time <- system.time(lapply(simulations,k_estimate))
print(r_sims_time) #606 seconds

#calc time in cpp
cpp_sims_time <- system.time(lapply(simulations,k_estimate_cpp))
print(cpp_sims_time) #1.1 seconds


#calculate actual values
k_vals_r = lapply(simulations,k_estimate) #wayyyy too slow
k_vals_cpp = lapply(simulations,k_estimate_cpp)


#compare 
comp <- mapply(identical,k_vals_r,k_vals_cpp)
k_vals_cpp[!comp] #list of not identical values is empty -> results match 

```




calculate w

```{r}


calc_a1 <- function(n) {
  a_1 = 0
  for(i in 1:(n-1)) {
    a_1 = a_1 + 1/i
  }
  
  return (a_1)
}

w_estimate <- function(s,n) {
  
  if(n == 0) {
    print("n must be positive!")
    return
  }

  a_1 = calc_a1(n)
  
  w = s / a_1
  
  return(w)
  
}

# ex = list(
#   c("0010100101"),
#   c("1001011101"),
#   c("1111111010")
# )
# print(ex)
# 
# 
# s_0 = nchar(ex[[1]])
# s_0
# n_0 = length(ex)
# 
# w = w_estimate(s_0,n_0)
# w



 

```

calculate Tajima's D

```{r}

calc_a2 <- function(n) {
  a_2 = 0
  for(i in 1:(n-1)) {
    a_2 = a_2 + (1/i)^2 
  }
  
  return (a_2)
}


D_estimation <- function(k,w,S,n) {
  
  if(n == 0 || n == 1) {
    print("ERROR: n must be greater than 1!")
    return
  }
  
  a_1 = calc_a1(n)
  a_2 = calc_a2(n)
  
  b_1 = (n + 1) / (3 * (n - 1))
  b_2 = (2 * (n^2 + n + 3)) / (9 * n * (n - 1))
  
  c_1 = b_1 - 1/a_1
  c_2 = b_2 - (n + 2) / (a_1 * n) + (a_2) / (a_1^2)
  
  e_1 = c_1/a_1
  e_2 = c_2/ (a_1^2 + a_2)
  
  
  d_num = k - w
  d_denom = (e_1 * S) + (e_2 * S) * (S - 1)
  
  D = d_num / sqrt(d_denom)
  
  return(D)
  
  
}



```

```{r}

tajimas_D <- function(simulation, show=0) {
  
  #calculate k
  k = k_estimate_cpp(simulation)
  
  
  #calculate w
  s = nchar(simulation[[1]])
  n = length(simulation)
  
  w = w_estimate(s,n)
  
  
  #calculate D
  d = D_estimation(k,w,s,n)
  
  
  if(show != 0) {
    print(paste("k:", k))
    print(paste("w:",w))
    print(paste("Tajima's D: ", d))
  }
    
  
  result <- c(k = k, w = w, d = d)
  return(result)
  
  
}

#calculate the parameters for all simulations
sims_params = sapply(simulations,tajimas_D)

#calculate the parameters for observed data
obs_params = tajimas_D(obs_data)
obs_params[1]

```


We now have calculated all 3 parameters for all of our simulations, as well as, the observed dataset. Before we try to approximate the parameter that calculated our observations, we have to normalize the simulations' data.

```{r}

#function takes as input a vector containing values of a parameter
#and returns a vector of the parameter's normalized values 
normalize_param <- function(param_vec) {
  
  params_mean = mean(param_vec)
  params_std = sqrt(var(param_vec))
  
  params_norm = (param_vec - params_mean) / params_std
  
  return(params_norm)
  
  
}

normalize_obs_param <- function(obs_param, sim_param_vec) {
  
  params_mean = mean(sim_param_vec)
  params_std = sqrt(var(sim_param_vec))
  
  param_norm = (obs_param - params_mean) / params_std
  
  return (param_norm)
}

#normalize sims' parameters
norm_k = normalize_param(sims_params[1,])
norm_w = normalize_param(sims_params[2,])
norm_d = normalize_param(sims_params[3,])

#normalize observed parameters
obs_norm_k = normalize_obs_param(obs_params[1],sims_params[1,])
obs_norm_w = normalize_obs_param(obs_params[2],sims_params[2,])
obs_norm_d = normalize_obs_param(obs_params[3],sims_params[3,])


```







